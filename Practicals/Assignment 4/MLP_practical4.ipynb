{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 60000-level section\n",
    "\n",
    "Instead of the SVM, let's use a perceptron as a classifier. And train it to recognize all 101 CALTECH classes (not just 3 or 10). First, use just one fully connected layer (hence a linear classsification). Next, following the \"sky is the limit\" sentence, try a few MLP architectures to see which one works best for your classes. **Remember to change your runtime type to GPU! (in menu above: Runtime -> Change runtime type -> GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Student:        Byron Dowling\n",
    "    Class:          Computer Vision (CSE 60535)\n",
    "    Term:           University of Notre Dame, Fall 2023\n",
    "    Assignment:     Practical #4 : Deep Learning-based Object Detection\n",
    "\"\"\"\n",
    "\n",
    "# Two lines below (when uncommented) allow you to track the time spent on each cell, if you wanted\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import Compose, Resize\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's download and extract the Caltech101 dataset.\n",
    "!wget -c https://notredame.box.com/shared/static/o5hw6ljq7x00smui4ixo9akxwlq2dkib.gz -O caltech101.tar.gz\n",
    "%mkdir ./caltech101/\n",
    "!tar -zxf caltech101.tar.gz -C ./caltech101/\n",
    "\n",
    "# We need to convert PIL images in to OpenCV images\n",
    "class ToCV2(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        #image, label = sample['image'], sample['label']\n",
    "\n",
    "        image = np.array(sample.convert('RGB'))\n",
    "        image = image[:, :, ::-1].copy()\n",
    "\n",
    "        return image\n",
    "\n",
    "caltech101_dataset = datasets.Caltech101(root='./', transform=Compose([Resize((224, 224)), ToCV2()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we split the dataset into train and validation partitions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for image, label in tqdm(caltech101_dataset):\n",
    "    X.append(image)\n",
    "    Y.append(int(label))\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are utilizing Keras API to load the pretrained VGG16 model as our feature extractor for training SVM\n",
    "model = VGG16(weights='imagenet')\n",
    "cnn_codes = 'fc2'\n",
    "features_model = Model(inputs=model.input, outputs=model.get_layer(cnn_codes).output)\n",
    "\n",
    "# Next, we can train using our splits and try out different model architectures\n",
    "# Inform the optimizer that we are not going to fine-tune the VGG (feature extraction) model\n",
    "features_model.trainable = False\n",
    "\n",
    "# Create your MLP (instead of SVM) on top of the VGG model\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = features_model(inputs, training=False)\n",
    "\n",
    "# *** Task 4a ***\n",
    "# Add several layers between the VGG model and the output layer.\n",
    "# These can be fully-connected (\"Dense\"), convolutional, pooling or dropout layers.\n",
    "# The syntax always will be x = tf.keras.layers.LAYER(...)(x), where LAYER is the correct name\n",
    "# you can find in tensorflow documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n",
    "D1 = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "drop_out1 = tf.keras.layers.Dropout(rate=0.25)(D1)\n",
    "D2 = tf.keras.layers.Dense(128, activation='relu')(drop_out1)\n",
    "drop_out2 = tf.keras.layers.Dropout(rate=0.25)(D2)\n",
    "\n",
    "# *** Task 4b ***\n",
    "# Use outputs = tf.keras.layers.Dense(...)(x) to define the correct output of your single-layer perceptron,\n",
    "# that is at least select the correct number of output neurons and the softmax activation function\n",
    "outputs = tf.keras.layers.Dense(101, activation='softmax')(drop_out2)\n",
    "\n",
    "full_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(full_model.summary())\n",
    "\n",
    "# *** Task 4c ***\n",
    "# Number of epochs (= number of presentations of the full training set to the model while training)\n",
    "# is arbitrarily set to 3 now. But you may increase this number and observe the validation (not training) loss.\n",
    "# When it stagnates, it's a good moment to stop training and take these weights to your final model.\n",
    "epochs = 15\n",
    "\n",
    "\n",
    "\n",
    "# Compile (= build) the model, define when to save checkpoints, and train it!\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"caltech101.h5\", monitor=\"val_accuracy\",verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "full_model.fit(x_train, y_train, epochs=epochs, verbose=1, validation_data = (x_valid, y_valid), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
